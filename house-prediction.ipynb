{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-01T10:35:17.317478Z","iopub.status.idle":"2022-09-01T10:35:17.317886Z","shell.execute_reply.started":"2022-09-01T10:35:17.317692Z","shell.execute_reply":"2022-09-01T10:35:17.317712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# House Price Prediction\n\nIn the projection we would be predicting the prices for the houses based on different features. Every buyer has a different requirements about their dream house and in this project we would analyse how each attribute contribute to the house pricing and the trends by year.","metadata":{}},{"cell_type":"markdown","source":"## Goals of the Study\n\n- Predict the House Price based on the attributes \n- The Current data has following properties:\n    - `79 features` with `Numerical` and `categorical` columns \n    - `1460` records in the dataset.\n    - `SalePrice` is the Label to be predicted\n    - The Sales data are from `2006` to `2010`\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"#### 1.1 Import Libraries and configuration","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.api.types import CategoricalDtype\n\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_regression\nimport os\nsns.set(style=\"whitegrid\", color_codes=True)\nsns.set(font_scale=1)\n'''Ignore deprecation and future, and user warnings.'''\nimport warnings as wrn\nwrn.filterwarnings('ignore', category = DeprecationWarning) \nwrn.filterwarnings('ignore', category = FutureWarning) \nwrn.filterwarnings('ignore', category = UserWarning) \nplt.rcParams[\"figure.figsize\"] = (10,5)\n\nhouse_attributes = dict()\nhouse_mapping = dict()\n\nfile_name = {\"train\": \"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\", \n             \"test\": \"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\"}\ndict_file_name = \"/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\"","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:17.321846Z","iopub.execute_input":"2022-09-01T10:35:17.322250Z","iopub.status.idle":"2022-09-01T10:35:19.044980Z","shell.execute_reply.started":"2022-09-01T10:35:17.322214Z","shell.execute_reply":"2022-09-01T10:35:19.043615Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from IPython.core.display import HTML\n\n# Reading the mapping file\ndef load_dictionary(data_dictory):\n    '''Read the data dictionary and create a Map'''\n    key, value = None, None\n\n    with open(data_dictory) as file:\n        lines = file.readlines()\n        for line in lines:\n            if len(line.strip()) > 0:\n                if len(line[0].strip()) > 0:\n                    key, value = line.split(\":\")\n                    house_attributes[key.strip()] = value.strip()\n                    house_mapping[key] = dict()\n                elif key:\n                    attr, *attr_value = line.strip().split(\"\\t\")\n                    house_mapping[key][attr] = \" \".join(attr_value)\n    return house_mapping, house_attributes\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.047789Z","iopub.execute_input":"2022-09-01T10:35:19.048414Z","iopub.status.idle":"2022-09-01T10:35:19.059922Z","shell.execute_reply.started":"2022-09-01T10:35:19.048378Z","shell.execute_reply":"2022-09-01T10:35:19.058006Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"house_mapping,house_attributes = load_dictionary(dict_file_name)\nfor key in house_attributes:\n    print(f\"\"\"{key} : {house_attributes[key]}\n    ---------------------------------------------\n    {house_mapping[key]}\n    \"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.062151Z","iopub.execute_input":"2022-09-01T10:35:19.063001Z","iopub.status.idle":"2022-09-01T10:35:19.084354Z","shell.execute_reply.started":"2022-09-01T10:35:19.062954Z","shell.execute_reply":"2022-09-01T10:35:19.083186Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Reading the House Price data","metadata":{}},{"cell_type":"code","source":"houseprice = pd.read_csv(file_name['train'], index_col=0)\nhouseprice_test = pd.read_csv(file_name['test'], index_col=0)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.087356Z","iopub.execute_input":"2022-09-01T10:35:19.088165Z","iopub.status.idle":"2022-09-01T10:35:19.184610Z","shell.execute_reply.started":"2022-09-01T10:35:19.088095Z","shell.execute_reply":"2022-09-01T10:35:19.183460Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"numerical_columns = houseprice.select_dtypes(include=np.number)\ncategorical_columns = houseprice.select_dtypes(include=['object'])\nprint(f\"\"\"Listing the Columns({len(houseprice.columns)} columns):\n\nNumerical columns({len(numerical_columns)}) :  {numerical_columns.columns.tolist()}\n\nCategorical columns({len(categorical_columns)}) :  {categorical_columns.columns.tolist()}\n\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.188345Z","iopub.execute_input":"2022-09-01T10:35:19.188841Z","iopub.status.idle":"2022-09-01T10:35:19.204598Z","shell.execute_reply.started":"2022-09-01T10:35:19.188796Z","shell.execute_reply":"2022-09-01T10:35:19.203176Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### 1.3 Summarize the data","metadata":{}},{"cell_type":"code","source":"print(f\"The dataset has data for {houseprice.shape[0]} transaction and columns {houseprice.shape[1]}\")\nprint(\"Number of dupicated records in the dataset :\",len(houseprice[houseprice.duplicated()]))\npd.options.display.float_format = '{:20.2f}'.format\nprint(\"Displaying the first 5 records of data:\")\nhouseprice.head(n=5)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.206674Z","iopub.execute_input":"2022-09-01T10:35:19.207647Z","iopub.status.idle":"2022-09-01T10:35:19.286942Z","shell.execute_reply.started":"2022-09-01T10:35:19.207576Z","shell.execute_reply":"2022-09-01T10:35:19.285890Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### 1.3.1 Label - Sales Price \nLet’s get statistical information about the label","metadata":{}},{"cell_type":"code","source":"stat_saleprice = houseprice.SalePrice.describe()\nprint(f\"\"\"Statistics for the SalesPrice:\n---------------------------\ncount    : {stat_saleprice['count']},\nmean     : ${stat_saleprice['mean']},\nstd      : ${stat_saleprice['std']},\nmin      : ${stat_saleprice['min']},\n25%      : ${stat_saleprice['25%']},\n50%      : ${stat_saleprice['50%']},\n75%      : ${stat_saleprice['75%']},\nmax      : ${stat_saleprice['max']},\nIQR      : ${stat_saleprice['25%']} - ${stat_saleprice['75%']}\nskew     : {houseprice.SalePrice.skew()}\nskew(log): {np.log(houseprice.SalePrice).skew()}\nkurt     : {houseprice.SalePrice.kurt()}\nkurt(log): {np.log(houseprice.SalePrice).kurt()}\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.288822Z","iopub.execute_input":"2022-09-01T10:35:19.289612Z","iopub.status.idle":"2022-09-01T10:35:19.308773Z","shell.execute_reply.started":"2022-09-01T10:35:19.289567Z","shell.execute_reply":"2022-09-01T10:35:19.307297Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### 1.3.2 Numerical columns  \nLet’s get statistical information about the Numerical Columns","metadata":{}},{"cell_type":"code","source":"numerical_columns = houseprice.select_dtypes(include=[np.number]).drop(columns=['SalePrice']).columns.tolist()\nuniqueValCount=houseprice[numerical_columns].nunique()\n#uniqueValCount[uniqueValCount<50].sort_values(ascending=False).index\nnumerical_discrete=uniqueValCount[uniqueValCount<50].index.tolist()\ntime_columns = ['YearBuilt','YearRemodAdd','YrSold','MoSold','GarageYrBlt']\nnumerical_discrete = [col for col in numerical_discrete if col not in time_columns]\nnumerical_columns = [col for col in numerical_columns if col not in numerical_discrete+time_columns]","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.310730Z","iopub.execute_input":"2022-09-01T10:35:19.312442Z","iopub.status.idle":"2022-09-01T10:35:19.337145Z","shell.execute_reply.started":"2022-09-01T10:35:19.312391Z","shell.execute_reply":"2022-09-01T10:35:19.335960Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def data_range_nooutlier(data, level=1, continuous=False, log=False):\n    def pct_method(data, level):\n        # The percentile method cuts off a predefined percentage(99%)\n        # amount from the top and the bottom of a distribution\n        upper = np.percentile(data, 100 - level)\n        lower = np.percentile(data, level)\n        # Returning the upper and lower limits\n        return [lower, upper]\n    \n    def iqr_method(data):\n        # The interquartile range approach first calculates the interquartile range (IQR) of the data.\n        # This IQR is then multiplied with 1.5. Any data that is then further away than the 75 percentile\n        # plus 1.5*IQR or 25 percentile minus 1.5*IQR is classified as an outlier.\n        perc_75 = np.percentile(data, 75)\n        perc_25 = np.percentile(data, 25)\n        iqr_range = perc_75 - perc_25\n        # Obtaining the lower and upper bound\n        iqr_upper = perc_75 + 1.5 * iqr_range\n        iqr_lower = perc_25 - 1.5 * iqr_range\n        # Returning the upper and lower limits\n        return [iqr_lower, iqr_upper]\n    \n    def std_method(data):\n        # given a normally distributed variable, approximately 99.7%\n        # of the data is within three standard deviations\n        std = np.std(data)\n        upper_3std = np.mean(data) + 3 * std\n        lower_3std = np.mean(data) - 3 * std\n        # Returning the upper and lower limits\n        return [lower_3std, upper_3std]\n    \n    # Taking logs is specified\n    data = data[~data.isna()]\n\n    if log is True:\n        data = np.log1p(data)\n    # Obtaining the ranges\n    pct_range = pct_method(data, level)\n    iqr_range = iqr_method(data)\n    std_range = std_method(data)\n\n    if continuous is False:\n        # Setting the lower limit fixed for discrete variables\n        low_limit = np.min(data)\n        high_limit = np.max([pct_range[1], iqr_range[1], std_range[1]])\n    elif continuous is True:\n        low_limit = np.min([pct_range[0], iqr_range[0], std_range[0]])\n        high_limit = np.max([pct_range[1], iqr_range[1], std_range[1]])\n    # Restrict the data with the minimum and maximum\n    # outlier = data.between(low_limit, high_limit)\n    # Return boolean\n    return low_limit, high_limit","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.342184Z","iopub.execute_input":"2022-09-01T10:35:19.343445Z","iopub.status.idle":"2022-09-01T10:35:19.362468Z","shell.execute_reply.started":"2022-09-01T10:35:19.343393Z","shell.execute_reply":"2022-09-01T10:35:19.361002Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"numerical_columns_summary = houseprice.loc[:,numerical_columns].describe().T\nnumerical_columns_summary['skew']=numerical_columns_summary.index.map(lambda x: houseprice[x].skew() )\nnumerical_columns_summary['skew(log1p)']=numerical_columns_summary.index.map(lambda x: np.log1p(houseprice[x]).skew() )\nnumerical_columns_summary['cutoffmax']=numerical_columns_summary.index.map(lambda x: data_range_nooutlier(houseprice[x],continuous=True)[1])\nnumerical_columns_summary","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.370460Z","iopub.execute_input":"2022-09-01T10:35:19.371703Z","iopub.status.idle":"2022-09-01T10:35:19.505474Z","shell.execute_reply.started":"2022-09-01T10:35:19.371654Z","shell.execute_reply":"2022-09-01T10:35:19.504189Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(f\"\"\"{len(numerical_columns_summary)} Numerical columns with\n\nMissing Records   : {numerical_columns_summary[numerical_columns_summary['count']<len(houseprice)].index.tolist()}\nZero units        : {numerical_columns_summary[numerical_columns_summary['min']==0].index.tolist()}\nSkew > 5          : {numerical_columns_summary[numerical_columns_summary['skew']>5].index.tolist()}\nPossible outliers : {numerical_columns_summary[numerical_columns_summary['max']>numerical_columns_summary['mean'] + 3*numerical_columns_summary['std']].index.tolist()}\n\"\"\")\n\nfor col in ['LotArea','GrLivArea']:\n    print(f\"\"\"{col} Summary:\n---------------------------\nAverage {col} for the dataset {numerical_columns_summary.loc[col]['mean']} ft^2 with standard deviation {numerical_columns_summary.loc[col]['std']} ft^2\nThe {col} ranges from {numerical_columns_summary.loc[col]['min']} to {numerical_columns_summary.loc[col]['max']} with median of {numerical_columns_summary.loc[col]['50%']}\nCutoff Max for outlier removal: {data_range_nooutlier(houseprice[col],continuous=True)[1]:.2f}\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.507587Z","iopub.execute_input":"2022-09-01T10:35:19.508507Z","iopub.status.idle":"2022-09-01T10:35:19.535302Z","shell.execute_reply.started":"2022-09-01T10:35:19.508456Z","shell.execute_reply":"2022-09-01T10:35:19.533892Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#### 1.3.3 Numerical-Discrete columns","metadata":{}},{"cell_type":"code","source":"numerical_discrete_summary = houseprice[numerical_discrete].applymap(str).describe().transpose()\nnumerical_discrete_summary['count'] = numerical_discrete_summary.index.map(lambda x: len(houseprice[~houseprice[x].isna()]))\nnumerical_discrete_summary['top'] = numerical_discrete_summary.apply(lambda x: house_mapping[x.name][x['top']] if x.name in house_mapping and house_mapping[x.name]  else x['top'] , axis=1)\nnumerical_discrete_summary","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.537502Z","iopub.execute_input":"2022-09-01T10:35:19.538385Z","iopub.status.idle":"2022-09-01T10:35:19.630668Z","shell.execute_reply.started":"2022-09-01T10:35:19.538324Z","shell.execute_reply":"2022-09-01T10:35:19.629470Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(f\"\"\"{len(numerical_discrete_summary)} Numerical-Discrete columns with\n\nMissing Records   : {numerical_discrete_summary[numerical_discrete_summary['count']<len(houseprice)].index.tolist()}\n\"\"\")\n\nfor col in ['MSSubClass','OverallQual','GarageCars']:\n    print(f\"\"\"{col} Summary:\n---------------------------\nNumber for Unique Values  : {numerical_discrete_summary.loc[col, 'unique']}\nValue with most occurances: {numerical_discrete_summary.loc[col, 'top']} ({numerical_discrete_summary.loc[col, 'freq']})\n\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.634399Z","iopub.execute_input":"2022-09-01T10:35:19.634850Z","iopub.status.idle":"2022-09-01T10:35:19.641873Z","shell.execute_reply.started":"2022-09-01T10:35:19.634816Z","shell.execute_reply":"2022-09-01T10:35:19.641048Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#### 1.3.4 Time columns","metadata":{}},{"cell_type":"code","source":"time_columns_summary = pd.DataFrame(index=time_columns)\ntime_columns_summary['count'] = time_columns_summary.index.map(lambda x: len(houseprice[~houseprice[x].isna()])).astype(\"int\")\ntime_columns_summary['unique'] = time_columns_summary.index.map(lambda x: houseprice[x].nunique()).astype(\"int\")\ntime_columns_summary['min'] = time_columns_summary.index.map(lambda x: houseprice[x].min()).astype(\"int\")\ntime_columns_summary['max'] = time_columns_summary.index.map(lambda x: houseprice[x].max()).astype(\"int\")\ntime_columns_summary['top'] = time_columns_summary.index.map(lambda x: houseprice[x].value_counts().idxmax()).astype(\"int\")\ntime_columns_summary['freq'] = time_columns_summary.index.map(lambda x: houseprice[x].value_counts().max()).astype(\"int\")\ntime_columns_summary","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.643441Z","iopub.execute_input":"2022-09-01T10:35:19.644023Z","iopub.status.idle":"2022-09-01T10:35:19.688863Z","shell.execute_reply.started":"2022-09-01T10:35:19.643990Z","shell.execute_reply":"2022-09-01T10:35:19.688079Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(f\"\"\"{len(time_columns_summary)} Time columns with\n\nMissing Records   : {time_columns_summary[time_columns_summary['count']<len(houseprice)].index.tolist()}\n\"\"\")\n\nfor col in ['YearBuilt','YearRemodAdd','YrSold','GarageYrBlt']:\n    print(f\"\"\"{col} Summary:\n---------------------------\nNumber for Unique Values  : {time_columns_summary.loc[col, 'unique']}\nValue with most occurances: {time_columns_summary.loc[col, 'top']} ({time_columns_summary.loc[col, 'freq']})\nRange                     : {time_columns_summary.loc[col, 'min']} - {time_columns_summary.loc[col, 'max']} ({time_columns_summary.loc[col, 'max'] - time_columns_summary.loc[col, 'min']})\n\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.690292Z","iopub.execute_input":"2022-09-01T10:35:19.690860Z","iopub.status.idle":"2022-09-01T10:35:19.699486Z","shell.execute_reply.started":"2022-09-01T10:35:19.690827Z","shell.execute_reply":"2022-09-01T10:35:19.698533Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### 1.3.5 Categorical Attributes","metadata":{}},{"cell_type":"code","source":"cat_summary = houseprice.describe(include=[object]).transpose()\ncat_summary['top'] = cat_summary.apply(lambda x: house_mapping[x.name][x['top']] if x.name in house_mapping and x['top'] in house_mapping[x.name]  else x['top'] , axis=1)\ncat_summary","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.701093Z","iopub.execute_input":"2022-09-01T10:35:19.702359Z","iopub.status.idle":"2022-09-01T10:35:19.784916Z","shell.execute_reply.started":"2022-09-01T10:35:19.702319Z","shell.execute_reply":"2022-09-01T10:35:19.784085Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(f\"\"\"{len(cat_summary)} Categorical columns with\n\nMissing Records   : {cat_summary[cat_summary['count']<len(houseprice)].index.tolist()}\n\"\"\")\n\nfor col in ['MSZoning','SaleCondition','SaleCondition','Electrical','Heating','FireplaceQu']:\n    print(f\"\"\"{col} Summary:\n---------------------------\nNumber for Unique Values  : {cat_summary.loc[col, 'unique']}\nValue with most occurances: {cat_summary.loc[col, 'top']} ({cat_summary.loc[col, 'freq']})\n\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.786379Z","iopub.execute_input":"2022-09-01T10:35:19.786780Z","iopub.status.idle":"2022-09-01T10:35:19.796573Z","shell.execute_reply.started":"2022-09-01T10:35:19.786737Z","shell.execute_reply":"2022-09-01T10:35:19.795225Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### 1.4 Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"#### 1.4.1 Dealing with Missing Value","metadata":{}},{"cell_type":"code","source":"# Getting the number of missing values in each column\nnum_missing = houseprice.isna().sum()\n# Excluding columns that contains 0 missing values\nnum_missing = num_missing[num_missing > 0]\n# Getting the percentages of missing values\npercent_missing = num_missing * 100 / houseprice.shape[0]\n# Concatenating the number and perecentage of missing values\n# into one dataframe and sorting it\npd.concat([num_missing, percent_missing], axis=1,\nkeys=['Missing Values', 'Percentage']).\\\nsort_values(by=\"Missing Values\", ascending=False).T.style.background_gradient(axis=1) ","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.798501Z","iopub.execute_input":"2022-09-01T10:35:19.799245Z","iopub.status.idle":"2022-09-01T10:35:19.915675Z","shell.execute_reply.started":"2022-09-01T10:35:19.799197Z","shell.execute_reply":"2022-09-01T10:35:19.914446Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\n# Getting the number of missing values in each column\nnum_missing = houseprice_test.isna().sum()\n# Excluding columns that contains 0 missing values\nnum_missing = num_missing[num_missing > 0]\n# Getting the percentages of missing values\npercent_missing = num_missing * 100 / houseprice_test.shape[0]\n# Concatenating the number and perecentage of missing values\n# into one dataframe and sorting it\npd.concat([num_missing, percent_missing], axis=1,\nkeys=['Missing Values', 'Percentage']).\\\nsort_values(by=\"Missing Values\", ascending=False).T.style.background_gradient(axis=1) ","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.917253Z","iopub.execute_input":"2022-09-01T10:35:19.917674Z","iopub.status.idle":"2022-09-01T10:35:19.976857Z","shell.execute_reply.started":"2022-09-01T10:35:19.917643Z","shell.execute_reply":"2022-09-01T10:35:19.976049Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.1 PoolQC \nPool quality has 99.5 % missing values, which is very high. ","metadata":{}},{"cell_type":"code","source":"houseprice.groupby( ['PoolQC'],as_index=False, dropna=False)['PoolArea'].min().T","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:19.978127Z","iopub.execute_input":"2022-09-01T10:35:19.979146Z","iopub.status.idle":"2022-09-01T10:35:20.002309Z","shell.execute_reply.started":"2022-09-01T10:35:19.979081Z","shell.execute_reply":"2022-09-01T10:35:20.001090Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Pool Quality is NaN when Pool Area is 0. So we can impute the value with NA = No Pool","metadata":{}},{"cell_type":"code","source":"#NA = No Pool as per data description\nhouseprice[\"PoolQC\"].fillna(\"NA\", inplace=True)\nhouseprice_test[\"PoolQC\"].fillna(\"NA\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.003621Z","iopub.execute_input":"2022-09-01T10:35:20.004113Z","iopub.status.idle":"2022-09-01T10:35:20.010856Z","shell.execute_reply.started":"2022-09-01T10:35:20.004064Z","shell.execute_reply":"2022-09-01T10:35:20.009448Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.2 MiscFeature\nMiscellaneous feature not covered in other categories- has ~96% null values","metadata":{}},{"cell_type":"code","source":"houseprice[\"MiscFeature\"].value_counts(dropna=False).to_frame().T\n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.012090Z","iopub.execute_input":"2022-09-01T10:35:20.012945Z","iopub.status.idle":"2022-09-01T10:35:20.028058Z","shell.execute_reply.started":"2022-09-01T10:35:20.012909Z","shell.execute_reply":"2022-09-01T10:35:20.026730Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#NA = None as per data description\nhouseprice[\"MiscFeature\"].fillna(\"NA\", inplace=True)\nhouseprice_test[\"MiscFeature\"].fillna(\"NA\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.029662Z","iopub.execute_input":"2022-09-01T10:35:20.030275Z","iopub.status.idle":"2022-09-01T10:35:20.036062Z","shell.execute_reply.started":"2022-09-01T10:35:20.030239Z","shell.execute_reply":"2022-09-01T10:35:20.035291Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.3 Alley\nType of alley access to property- has ~93% null values.\n\nSetting the null values as No Alley","metadata":{}},{"cell_type":"code","source":"#NA = No Alley\nhouseprice['Alley'].fillna('NA', inplace=True)\nhouseprice_test['Alley'].fillna('NA', inplace=True)\nhouseprice[\"Alley\"].value_counts(dropna=False).to_frame().T","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.037395Z","iopub.execute_input":"2022-09-01T10:35:20.037878Z","iopub.status.idle":"2022-09-01T10:35:20.058444Z","shell.execute_reply.started":"2022-09-01T10:35:20.037846Z","shell.execute_reply":"2022-09-01T10:35:20.057179Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.4 Fence\nFence quality- has ~80% null values.\n\nSetting the null values as No Fence","metadata":{}},{"cell_type":"code","source":"#NA = No Fence\nhouseprice['Fence'].fillna('NA', inplace=True)\nhouseprice_test['Fence'].fillna('NA', inplace=True)\nhouseprice[\"Fence\"].value_counts(dropna=False).to_frame().T","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.059914Z","iopub.execute_input":"2022-09-01T10:35:20.060283Z","iopub.status.idle":"2022-09-01T10:35:20.075786Z","shell.execute_reply.started":"2022-09-01T10:35:20.060249Z","shell.execute_reply":"2022-09-01T10:35:20.074661Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.5 FireplaceQu\nFireplace quality- has ~47% null values.\n","metadata":{}},{"cell_type":"code","source":"houseprice.groupby( ['FireplaceQu'],as_index=False, dropna=False)['Fireplaces'].min().T","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.077742Z","iopub.execute_input":"2022-09-01T10:35:20.078095Z","iopub.status.idle":"2022-09-01T10:35:20.099305Z","shell.execute_reply.started":"2022-09-01T10:35:20.078063Z","shell.execute_reply":"2022-09-01T10:35:20.098160Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Fireplace is 0 where FireplaceQu is Nan, so setting as No Fireplace","metadata":{}},{"cell_type":"code","source":"houseprice['FireplaceQu'].fillna('NA', inplace=True)\nhouseprice_test['FireplaceQu'].fillna('NA', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.101001Z","iopub.execute_input":"2022-09-01T10:35:20.101595Z","iopub.status.idle":"2022-09-01T10:35:20.109018Z","shell.execute_reply.started":"2022-09-01T10:35:20.101559Z","shell.execute_reply":"2022-09-01T10:35:20.108259Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.6 LotFrontage\nLinear feet of street connected to property- has ~18% null values.\n\nWe assume that the missing values in this column indicates that the house\nis not connected to any street, and we fill in the missing values with 0","metadata":{}},{"cell_type":"code","source":"houseprice['LotFrontage'].fillna(0, inplace=True)\nhouseprice_test['LotFrontage'].fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.114490Z","iopub.execute_input":"2022-09-01T10:35:20.115130Z","iopub.status.idle":"2022-09-01T10:35:20.120513Z","shell.execute_reply.started":"2022-09-01T10:35:20.115058Z","shell.execute_reply":"2022-09-01T10:35:20.119703Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.7 GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond\nhas ~5.6% null values.\n\n- GarageType: Garage location\n- GarageYrBlt: Year garage was built\n- GarageFinish: Interior finish of the garage\n- GarageQual: Garage quality\n- GarageCond: Garage condition","metadata":{}},{"cell_type":"code","source":"#getting the records where garage attributes has null\ngarage_columns = [col for col in houseprice.columns if col.startswith(\"Garage\")]\nhouseprice[houseprice[garage_columns].isna().any(axis=1)][garage_columns].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.121864Z","iopub.execute_input":"2022-09-01T10:35:20.122486Z","iopub.status.idle":"2022-09-01T10:35:20.149984Z","shell.execute_reply.started":"2022-09-01T10:35:20.122452Z","shell.execute_reply":"2022-09-01T10:35:20.149070Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"**When the GarageCars is 0, the other values are NaN and Area is 0**\n\n- Setting the values to No Garage","metadata":{}},{"cell_type":"code","source":"for col in ['GarageType','GarageFinish','GarageQual','GarageCond']:\n    houseprice[col].fillna('NA', inplace=True)\n    houseprice_test[col].fillna('NA', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.155374Z","iopub.execute_input":"2022-09-01T10:35:20.156774Z","iopub.status.idle":"2022-09-01T10:35:20.166516Z","shell.execute_reply.started":"2022-09-01T10:35:20.156734Z","shell.execute_reply":"2022-09-01T10:35:20.165176Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Setting build year to 0\nhouseprice['GarageYrBlt'].fillna(0, inplace=True)\nhouseprice_test['GarageYrBlt'].fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.169613Z","iopub.execute_input":"2022-09-01T10:35:20.169979Z","iopub.status.idle":"2022-09-01T10:35:20.176702Z","shell.execute_reply.started":"2022-09-01T10:35:20.169945Z","shell.execute_reply":"2022-09-01T10:35:20.175268Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.8 BsmtExposure, BsmtFinType2, BsmtFinType1, BsmtCond, BsmtQual\n\nhas ~2.6% null values.\n\n- BsmtExposure: Refers to walkout or garden level walls\n- BsmtFinType1: Rating of basement finished area\n- BsmtFinType2: Rating of basement finished area (if multiple types)\n- BsmtCond: Evaluates the general condition of the basement\n- BsmtQual: Evaluates the height of the basement\n","metadata":{}},{"cell_type":"code","source":"bsmt_columns = [col for col in houseprice.columns if col.startswith(\"Bsmt\")]\nhouseprice[houseprice[bsmt_columns].isna().any(axis=1)][bsmt_columns].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.178632Z","iopub.execute_input":"2022-09-01T10:35:20.179046Z","iopub.status.idle":"2022-09-01T10:35:20.200347Z","shell.execute_reply.started":"2022-09-01T10:35:20.179012Z","shell.execute_reply":"2022-09-01T10:35:20.199338Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Three types of data\n- Bsmt data is either Nan or 0 : Marking those entries as No Basement\n- BsmtConf as TA and BsmtFinType2 as Nan : set as Unf\n- BsmtConf as TA and BsmtExposure as Nan : set as No","metadata":{}},{"cell_type":"code","source":"# Setting the values as NA as `Expose is Nan or No\n#Case 1\nhouseprice.loc[~pd.isnull(houseprice['BsmtCond']) & pd.isnull(houseprice['BsmtFinType2']),'BsmtFinType2']='Unf'\n#case 2\nhouseprice.loc[~pd.isnull(houseprice['BsmtCond']) & pd.isnull(houseprice['BsmtExposure']),'BsmtExposure']='No'\n#Case 3\nfor col in [\"BsmtExposure\", \"BsmtFinType2\", \"BsmtFinType1\", \"BsmtCond\", \"BsmtQual\"]:\n    houseprice[col].fillna('NA', inplace=True)\n    houseprice_test[col].fillna('NA', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.201745Z","iopub.execute_input":"2022-09-01T10:35:20.202066Z","iopub.status.idle":"2022-09-01T10:35:20.218558Z","shell.execute_reply.started":"2022-09-01T10:35:20.202035Z","shell.execute_reply":"2022-09-01T10:35:20.216804Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.9 MasVnrArea, MasVnrType\n\nhas ~0.5% null values.\n\n- MasVnrType: Masonry veneer type\n- MasVnrArea: Masonry veneer area in square feet","metadata":{}},{"cell_type":"code","source":"# set as 0 and None as per data definition\nhouseprice['MasVnrArea'].fillna(0, inplace=True)\nhouseprice_test['MasVnrArea'].fillna(0, inplace=True)\nhouseprice['MasVnrType'].fillna(\"None\", inplace=True)\nhouseprice_test['MasVnrType'].fillna(\"None\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.219552Z","iopub.execute_input":"2022-09-01T10:35:20.219889Z","iopub.status.idle":"2022-09-01T10:35:20.230462Z","shell.execute_reply.started":"2022-09-01T10:35:20.219857Z","shell.execute_reply":"2022-09-01T10:35:20.228818Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"##### 1.4.1.10 Electrical\n\nElectrical: Electrical system has 1 null value.","metadata":{}},{"cell_type":"code","source":"## Getting the Electrical used during the year build\nprint(\" Record is null when \\n \",houseprice.loc[houseprice['Electrical'].isna(),['YearBuilt','YearRemodAdd']])\nprint(\"\\n Getting the Electrical used during the period: \\n\", houseprice.loc[((houseprice['YearBuilt']==2006)  | (houseprice['YearRemodAdd']==2007)),'Electrical'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.232209Z","iopub.execute_input":"2022-09-01T10:35:20.232671Z","iopub.status.idle":"2022-09-01T10:35:20.251848Z","shell.execute_reply.started":"2022-09-01T10:35:20.232622Z","shell.execute_reply":"2022-09-01T10:35:20.251002Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"**Standard Circuit Breakers & Romex** was used during the year build 2006, so setting the Electrical value ","metadata":{}},{"cell_type":"code","source":"houseprice['Electrical'].fillna(\"SBrkr\", inplace=True)\nhouseprice_test['Electrical'].fillna(\"SBrkr\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.253089Z","iopub.execute_input":"2022-09-01T10:35:20.254088Z","iopub.status.idle":"2022-09-01T10:35:20.260369Z","shell.execute_reply.started":"2022-09-01T10:35:20.254051Z","shell.execute_reply":"2022-09-01T10:35:20.259429Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Getting the number of missing values in each column\nnum_missing = houseprice_test.isna().sum()\n# Excluding columns that contains 0 missing values\nnum_missing = num_missing[num_missing > 0]\n# Getting the percentages of missing values\npercent_missing = num_missing * 100 / houseprice_test.shape[0]\n# Concatenating the number and perecentage of missing values\n# into one dataframe and sorting it\npd.concat([num_missing, percent_missing], axis=1,\nkeys=['Missing Values', 'Percentage']).\\\nsort_values(by=\"Missing Values\", ascending=False).T.style.background_gradient(axis=1) \n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.261670Z","iopub.execute_input":"2022-09-01T10:35:20.262467Z","iopub.status.idle":"2022-09-01T10:35:20.302989Z","shell.execute_reply.started":"2022-09-01T10:35:20.262419Z","shell.execute_reply":"2022-09-01T10:35:20.301728Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"houseprice_test.loc[houseprice_test.isna().any(axis=1),\n                    num_missing.index.tolist()]\nhouseprice_test['MSZoning'].fillna(\"RL\", inplace=True)\nhouseprice_test['Utilities'].fillna(\"AllPub\", inplace=True)\nhouseprice_test['Exterior1st'].fillna('VinylSd', inplace=True)\nhouseprice_test['BsmtFinSF2'].fillna(0.00, inplace=True)\nhouseprice_test['BsmtUnfSF'].fillna(0.00, inplace=True)\nhouseprice_test['TotalBsmtSF'].fillna(0.00, inplace=True)\nhouseprice_test['BsmtFullBath'].fillna(0.00, inplace=True)\nhouseprice_test['BsmtHalfBath'].fillna(0.00, inplace=True)\nhouseprice_test['KitchenQual'].fillna('TA', inplace=True)\nhouseprice_test['Functional'].fillna('Typ', inplace=True)\nhouseprice_test['SaleType'].fillna('WD', inplace=True)\nhouseprice_test['GarageCars'].fillna(0.00, inplace=True)\nhouseprice_test['GarageArea'].fillna(0.00, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.304602Z","iopub.execute_input":"2022-09-01T10:35:20.305031Z","iopub.status.idle":"2022-09-01T10:35:20.325625Z","shell.execute_reply.started":"2022-09-01T10:35:20.304997Z","shell.execute_reply":"2022-09-01T10:35:20.324335Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### 1.5 Outliers","metadata":{}},{"cell_type":"markdown","source":"- There seems to be **outliers**, as max values more than double the 3rd quartile \n- There are features with 75 percentile value as 0 and values above 3rd quater","metadata":{}},{"cell_type":"code","source":"\ndef plot_hist_scatter(df, feature, target=\"SalePrice\", outlier=True, log=False, **kwargs):\n    if log:\n        feature_data = np.log1p(df[feature])\n    else:\n        feature_data = df[feature]\n    plt.figure(figsize=(2 * 5.2, 1 * 3.2))\n    \n    print(f\"skew={feature_data.skew()}, kurtosis={feature_data.kurtosis()}\")\n    \n    plt.subplot(1, 2, 1)\n    feature_data.hist(bins=50)\n    if outlier:\n        cuttoff_min, cuttoff_max = data_range_nooutlier(feature_data, log=False, **kwargs)\n        print(f\"Within range: between {cuttoff_min:.2f} and {cuttoff_max:.2f}\")\n        plt.axvspan(xmin=cuttoff_max, xmax=feature_data.max(), color=\"r\", alpha=0.5)\n    plt.xlabel(f\"{'log' if log else ''}{feature}\")\n    plt.ylabel(\"count\")\n    plt.title(f\"{'log' if log else ''}{feature} histogram\")\n    if feature != target:\n        plt.subplot(1, 2, 2)\n        plt.scatter(\n            x=feature_data,\n            y=df[target],\n            color=\"orange\",\n            edgecolors=\"#000000\",\n            linewidths=0.5,\n        )\n        plt.xlabel(feature)\n        plt.ylabel(f\"{target}\")\n        if outlier:\n            plt.axvspan(xmin=cuttoff_max, xmax=feature_data.max(), color=\"r\", alpha=0.5)\n    plt.show()\n\n\n# plotting bars\ndef plot_bar(df, columns):\n    cols = 3\n    rows = len(columns) // 3 + 1\n\n    plt.figure(figsize=(cols * 6.7, rows * 3.75))\n    i = 0\n    for row in range(rows):\n        for col in range(cols):\n            index = cols * row + col\n            if index >= len(columns):\n                break\n            plt.subplot(rows, cols, index + 1)\n            df.groupby(columns[i]).size().plot(\n                kind=\"bar\",\n            )\n            \n            i += 1\n\n\n# plotting box\ndef plot_box(df, y, columns):\n    cols = 3\n    rows = len(columns) // 3 + 1\n\n    plt.figure(figsize=(cols * 5.5, rows * 3.5))\n    i = 0\n    for row in range(rows):\n        for col in range(cols):\n            index = cols * row + col\n            if index >= len(columns):\n                break\n            plt.subplot(rows, cols, index + 1)\n            sns.boxplot(x=columns[i], y=y, data=df)\n\n            i += 1\n\n# plotting hist\ndef plot_hist(df, columns):\n    cols = 3\n    rows = len(columns) // 3 + 1\n\n    plt.figure(figsize=(cols * 5.5, rows * 3.5))\n    i = 0\n    for row in range(rows):\n        for col in range(cols):\n            index = cols * row + col\n            if index >= len(columns):\n                break\n            plt.subplot(rows, cols, index + 1)\n            df[columns[i]].hist(bins=50)\n            plt.ylabel(columns[i])\n\n            i += 1\n\n\n#plot scatter            \ndef plot_scatter(df,y, columns):\n    cols = 3\n    rows = len(columns) // 3 + 1\n\n    plt.figure(figsize=(cols * 7.5, rows * 5.2))\n    i = 0\n    for row in range(rows):\n        for col in range(cols):\n            index = cols * row + col\n            if index >= len(columns):\n                break\n            plt.subplot(rows, cols, index + 1)\n            sns.scatterplot(x=columns[i], y=y, data=df)\n\n            i += 1\n\n            \ndef calculateAnova(inpData,y, catCols, target):\n    inpData = inpData.join(y)\n    from scipy.stats import f_oneway\n    CatColumnList = []\n    for cat in catCols:\n        CatGroupList = inpData.groupby(cat)[target].apply(list)\n        anova = f_oneway(*CatGroupList)\n        if(anova[1]<0.05):\n            print('The column ', cat, ' is correlated with ', target, ' | P-Value: ',anova[1])\n            CatColumnList.append(cat)\n        else:\n            print('The column ', cat , ' is NOT correlated with ', target, ' | P-Value: ',anova[1])\n    \n    return(CatColumnList)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.327529Z","iopub.execute_input":"2022-09-01T10:35:20.327891Z","iopub.status.idle":"2022-09-01T10:35:20.353465Z","shell.execute_reply.started":"2022-09-01T10:35:20.327857Z","shell.execute_reply":"2022-09-01T10:35:20.352594Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"cuttoff = dict()\nfor col in numerical_columns:\n    cuttoff[col] = dict()\n    cuttoff[col]['min'], cuttoff[col]['max']= houseprice[col].min(),houseprice[col].max()\n    cuttoff[col]['cutoffmin'],cuttoff[col]['cutoffmax']=data_range_nooutlier(houseprice[col],continuous=True)\n    cuttoff[col]['p25'], cuttoff[col]['p75']= np.percentile(houseprice[col],[25,75])\n    cuttoff[col]['cutoffmin'] = cuttoff[col]['cutoffmin'] if cuttoff[col]['min'] < cuttoff[col]['cutoffmin'] else  cuttoff[col]['min']\n    plot_hist_scatter(houseprice,col, continuous=True)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:20.354718Z","iopub.execute_input":"2022-09-01T10:35:20.355040Z","iopub.status.idle":"2022-09-01T10:35:28.327514Z","shell.execute_reply.started":"2022-09-01T10:35:20.355009Z","shell.execute_reply":"2022-09-01T10:35:28.326401Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(cuttoff).T[['min','cutoffmin','p25','p75','cutoffmax','max']]","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:28.329156Z","iopub.execute_input":"2022-09-01T10:35:28.329630Z","iopub.status.idle":"2022-09-01T10:35:28.347141Z","shell.execute_reply.started":"2022-09-01T10:35:28.329585Z","shell.execute_reply":"2022-09-01T10:35:28.346221Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"## Finding the columns having High corelation with SalePrice\ncor_df =houseprice[numerical_columns + ['SalePrice']].corr()['SalePrice'].sort_values(key=abs, ascending=False).to_frame()\ncor_df.style.background_gradient(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:28.353637Z","iopub.execute_input":"2022-09-01T10:35:28.354440Z","iopub.status.idle":"2022-09-01T10:35:28.384275Z","shell.execute_reply.started":"2022-09-01T10:35:28.354403Z","shell.execute_reply":"2022-09-01T10:35:28.383118Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"## Removing outliers for features having high correlation\n# Commented to validate the Outlier during EDA\n# adding a threshold for cutoffmax\nthreshold_ratio = 1.2\nfor col in cor_df[abs(cor_df['SalePrice']) >= 0.5].index.tolist():\n    if col != 'SalePrice':\n        print(f\"Adding cuttoff max for {col} : {cuttoff[col]['cutoffmax'] *threshold_ratio:.2f}\")\n        houseprice = houseprice[houseprice[col] <=cuttoff[col]['cutoffmax']*threshold_ratio]\nprint(\"Shape after removing outlier \", houseprice.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:28.385641Z","iopub.execute_input":"2022-09-01T10:35:28.386017Z","iopub.status.idle":"2022-09-01T10:35:28.403015Z","shell.execute_reply.started":"2022-09-01T10:35:28.385984Z","shell.execute_reply":"2022-09-01T10:35:28.401404Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"X = houseprice.copy()\nX_test = houseprice_test.copy()\ny = X.pop(\"SalePrice\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:28.404827Z","iopub.execute_input":"2022-09-01T10:35:28.405175Z","iopub.status.idle":"2022-09-01T10:35:28.413363Z","shell.execute_reply.started":"2022-09-01T10:35:28.405143Z","shell.execute_reply":"2022-09-01T10:35:28.412124Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"### 2.1 Univariate Analysis","metadata":{}},{"cell_type":"markdown","source":"#### 2.1.1 SalePrice","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(15, 3), sharey=False)\nfig.suptitle('Histogram')\n\n\nsns.histplot(data=y, kde=True, ax=axes[0])\naxes[0].set_title('SalePrice ')\n\n\nsns.histplot(ax=axes[1], data=np.log(y), kde=True)\naxes[1].set_title('Log of SalePrice')\naxes[1].set_xlabel('Log SalePrice')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:28.415014Z","iopub.execute_input":"2022-09-01T10:35:28.415549Z","iopub.status.idle":"2022-09-01T10:35:28.986642Z","shell.execute_reply.started":"2022-09-01T10:35:28.415497Z","shell.execute_reply":"2022-09-01T10:35:28.985396Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"- Sales price is positively skewed, and \n- **Log of data resembles a normal distribution**","metadata":{}},{"cell_type":"code","source":"# Sales per Square Feet\nSalePriceSF = y/X['GrLivArea']\nplt.hist(SalePriceSF, bins=15,color=\"gold\")\nplt.title(\"Sale Price per Square Foot\")\nplt.ylabel('Number of Sales')\nplt.xlabel('Price per square feet');\n#Average Sale Price per square feet \nprint(\"Average Sale Price per square feet: $\",SalePriceSF.mean())","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:28.988342Z","iopub.execute_input":"2022-09-01T10:35:28.988803Z","iopub.status.idle":"2022-09-01T10:35:29.303024Z","shell.execute_reply.started":"2022-09-01T10:35:28.988766Z","shell.execute_reply":"2022-09-01T10:35:29.301853Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"#### 2.1.2 Ordinal and Nominal","metadata":{}},{"cell_type":"code","source":"cat_columns=cat_summary.index.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:29.304556Z","iopub.execute_input":"2022-09-01T10:35:29.304869Z","iopub.status.idle":"2022-09-01T10:35:29.309984Z","shell.execute_reply.started":"2022-09-01T10:35:29.304839Z","shell.execute_reply":"2022-09-01T10:35:29.308778Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"plot_bar(X, numerical_discrete+ time_columns + cat_columns)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:29.311446Z","iopub.execute_input":"2022-09-01T10:35:29.311768Z","iopub.status.idle":"2022-09-01T10:35:49.023452Z","shell.execute_reply.started":"2022-09-01T10:35:29.311729Z","shell.execute_reply":"2022-09-01T10:35:49.022218Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"#### 2.1.3 Numerical","metadata":{}},{"cell_type":"code","source":"plot_hist(X,numerical_columns)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:49.025499Z","iopub.execute_input":"2022-09-01T10:35:49.026224Z","iopub.status.idle":"2022-09-01T10:35:53.234068Z","shell.execute_reply.started":"2022-09-01T10:35:49.026177Z","shell.execute_reply":"2022-09-01T10:35:53.232919Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Multi variate Analysis","metadata":{}},{"cell_type":"markdown","source":"#### 2.2.1 Correlation","metadata":{}},{"cell_type":"code","source":"X.columns","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:53.235587Z","iopub.execute_input":"2022-09-01T10:35:53.235942Z","iopub.status.idle":"2022-09-01T10:35:53.243990Z","shell.execute_reply.started":"2022-09-01T10:35:53.235890Z","shell.execute_reply":"2022-09-01T10:35:53.242780Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"plot_box(X,y,numerical_discrete+ time_columns + cat_columns)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:35:53.245622Z","iopub.execute_input":"2022-09-01T10:35:53.246040Z","iopub.status.idle":"2022-09-01T10:36:19.679130Z","shell.execute_reply.started":"2022-09-01T10:35:53.246005Z","shell.execute_reply":"2022-09-01T10:36:19.677701Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"From the above Plot\n- Utilities doesnot show any corelation with Sales Price and most of the data are AllPub\n- Having AC definitely escalates price of house.\n- Having 1 Kitchen of Excellent quality hikes house price like anything.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,7))\nsns.heatmap(X[numerical_columns].corr(), cmap='coolwarm', annot=True, annot_kws={'size':10}, )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:19.681355Z","iopub.execute_input":"2022-09-01T10:36:19.682259Z","iopub.status.idle":"2022-09-01T10:36:20.971583Z","shell.execute_reply.started":"2022-09-01T10:36:19.682212Z","shell.execute_reply":"2022-09-01T10:36:20.970170Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"- GrLivArea ,GarageCars,GarageArea ,TotalBsmtSF, 1stFlrSF  have more than 0.5 correlation with SalePrice.\n- EnclosedPorch and KitchenAbvGr have little negative correlation with target variable.","metadata":{}},{"cell_type":"code","source":"correlations=X.corr()\nattrs = correlations.iloc[:-1,:-1] # all except target\n\nthreshold = 0.5\nimportant_corrs = (attrs[abs(attrs) > threshold][attrs != 1.0]) \\\n    .unstack().dropna().to_dict()\n\nunique_important_corrs = pd.DataFrame(\n    list(set([(tuple(sorted(key)), important_corrs[key]) \\\n    for key in important_corrs])), \n        columns=['Attribute Pair', 'Correlation'])\n\n    # sorted by absolute value\nunique_important_corrs = unique_important_corrs.iloc[\n    abs(unique_important_corrs['Correlation']).argsort()[::-1]]\n\nunique_important_corrs.style.background_gradient(axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:20.973258Z","iopub.execute_input":"2022-09-01T10:36:20.973611Z","iopub.status.idle":"2022-09-01T10:36:21.007918Z","shell.execute_reply.started":"2022-09-01T10:36:20.973577Z","shell.execute_reply":"2022-09-01T10:36:21.006519Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"This shows multicollinearity. In regression, \"multicollinearity\" refers to features that are correlated with other features. Multicollinearity occurs when your model includes multiple factors that are correlated not just to your target variable, but also to each other.\n\nTo avoid this we can do 3 things:\n\n- Completely remove those variables\n- Make new feature by adding them or by some other operation.\n- Use PCA, which will reduce feature set to small number of non-collinear features.","metadata":{}},{"cell_type":"markdown","source":"#### 2.2.2 Visualization","metadata":{}},{"cell_type":"markdown","source":"##### 2.2.2.1 GarageArea - Sales Price\n\nSince GarageArea is highly correlated with the target variable, let's focus on it first.","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(y=y, x = 'GarageArea', data=X)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:21.009780Z","iopub.execute_input":"2022-09-01T10:36:21.010188Z","iopub.status.idle":"2022-09-01T10:36:21.233479Z","shell.execute_reply.started":"2022-09-01T10:36:21.010153Z","shell.execute_reply":"2022-09-01T10:36:21.231766Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"The above plot clearly shows a linear relationship between ‘SalePrice’ and ‘GarageArea’. The ‘SalePrice’ increases with an increase in ‘GarageArea’.","metadata":{}},{"cell_type":"markdown","source":"##### 2.2.2.2 OverallQual - Sales Price\n\nOverallQual is highly correlated with the target variable","metadata":{}},{"cell_type":"code","source":"sns.regplot(x='OverallQual', y=y, data=X, robust=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:21.234845Z","iopub.execute_input":"2022-09-01T10:36:21.235221Z","iopub.status.idle":"2022-09-01T10:36:25.150908Z","shell.execute_reply.started":"2022-09-01T10:36:21.235171Z","shell.execute_reply":"2022-09-01T10:36:25.149853Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"Obviously, there is a linear relationship between OverallQual and SalePri","metadata":{}},{"cell_type":"markdown","source":"##### 2.2.2.3 YearBuilt and SalePrice","metadata":{}},{"cell_type":"code","source":"sns.regplot(y=y, x='YearBuilt', data=X)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:25.152180Z","iopub.execute_input":"2022-09-01T10:36:25.152595Z","iopub.status.idle":"2022-09-01T10:36:25.643985Z","shell.execute_reply.started":"2022-09-01T10:36:25.152563Z","shell.execute_reply":"2022-09-01T10:36:25.642841Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"‘YearBuilt’ shows that the distribution is skewed towards the year 2000 and has a long tail which extends till 1900.\nThe linear relationship between the variables is clearer in cases of recently built houses.","metadata":{}},{"cell_type":"markdown","source":"##### 2.2.2.3 TotalBsmtSF and SalePrice","metadata":{}},{"cell_type":"code","source":"sns.regplot(x='TotalBsmtSF', y=y, data=X)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:25.645317Z","iopub.execute_input":"2022-09-01T10:36:25.646310Z","iopub.status.idle":"2022-09-01T10:36:26.124576Z","shell.execute_reply.started":"2022-09-01T10:36:25.646272Z","shell.execute_reply":"2022-09-01T10:36:26.123404Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"TotalBsmtSF is very highly correlated with our target variable SalePrice and also it follows a strong linear trend.","metadata":{}},{"cell_type":"markdown","source":"##### 2.2.2.3 GarageYrBlt and SalePrice","metadata":{}},{"cell_type":"code","source":"sns.regplot(y=y, x='GarageYrBlt', data=X)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:26.126372Z","iopub.execute_input":"2022-09-01T10:36:26.126723Z","iopub.status.idle":"2022-09-01T10:36:26.641652Z","shell.execute_reply.started":"2022-09-01T10:36:26.126691Z","shell.execute_reply":"2022-09-01T10:36:26.640534Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"X_test[X_test.isna().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:26.643159Z","iopub.execute_input":"2022-09-01T10:36:26.643528Z","iopub.status.idle":"2022-09-01T10:36:26.673407Z","shell.execute_reply.started":"2022-09-01T10:36:26.643495Z","shell.execute_reply":"2022-09-01T10:36:26.672189Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## 3. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Feature Addition","metadata":{}},{"cell_type":"code","source":"X[\"LivLotRatio\"] = X.GrLivArea / (X.LotArea + 1) \nX_test[\"LivLotRatio\"] = X_test.GrLivArea / (X.LotArea + 1)\nX[\"Spaciousness\"] = (X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]) / (X.TotRmsAbvGrd+1)\nX_test[\"Spaciousness\"] = (X_test[\"1stFlrSF\"] + X_test[\"2ndFlrSF\"]) / (X_test.TotRmsAbvGrd +1)\nX[\"MedNhbdArea\"] = X.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\nX_test[\"MedNhbdArea\"] = X_test.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\nX[\"PorchTypes\"] = X[[\n        \"WoodDeckSF\",\n        \"OpenPorchSF\",\n        \"EnclosedPorch\",\n        \"3SsnPorch\",\n        \"ScreenPorch\",\n    ]].gt(0.0).sum(axis=1)\nX_test[\"PorchTypes\"] = X_test[[\n        \"WoodDeckSF\",\n        \"OpenPorchSF\",\n        \"EnclosedPorch\",\n        \"3SsnPorch\",\n        \"ScreenPorch\",\n    ]].gt(0.0).sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:26.674630Z","iopub.execute_input":"2022-09-01T10:36:26.675228Z","iopub.status.idle":"2022-09-01T10:36:26.702997Z","shell.execute_reply.started":"2022-09-01T10:36:26.675193Z","shell.execute_reply":"2022-09-01T10:36:26.702174Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Feature Selection","metadata":{}},{"cell_type":"markdown","source":"#### 3.2.1 Continuous Vs Continuous -- Scatter Chart","metadata":{}},{"cell_type":"code","source":"numerical_columns=numerical_columns+['LivLotRatio','Spaciousness','MedNhbdArea']","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:26.708476Z","iopub.execute_input":"2022-09-01T10:36:26.709085Z","iopub.status.idle":"2022-09-01T10:36:26.713061Z","shell.execute_reply.started":"2022-09-01T10:36:26.709050Z","shell.execute_reply":"2022-09-01T10:36:26.712320Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"plot_scatter(X,y, numerical_columns)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:26.714616Z","iopub.execute_input":"2022-09-01T10:36:26.715311Z","iopub.status.idle":"2022-09-01T10:36:30.819361Z","shell.execute_reply.started":"2022-09-01T10:36:26.715276Z","shell.execute_reply":"2022-09-01T10:36:30.818360Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Based on correction, selecting the continous variables with correction > 0.4","metadata":{}},{"cell_type":"code","source":"corr_mat = X[numerical_columns].join(y).corr()\nselected_numerical_columns = corr_mat['SalePrice'][abs(corr_mat['SalePrice'])>=0.5].index.tolist()\nnonselected_numerical_columns = corr_mat['SalePrice'][abs(corr_mat['SalePrice'])<0.5].index.tolist()\nselected_numerical_columns","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:30.820876Z","iopub.execute_input":"2022-09-01T10:36:30.821485Z","iopub.status.idle":"2022-09-01T10:36:30.841034Z","shell.execute_reply.started":"2022-09-01T10:36:30.821448Z","shell.execute_reply":"2022-09-01T10:36:30.839590Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2.2 Categorical Vs Continuous -- Anova","metadata":{}},{"cell_type":"code","source":"#target = 'SalePrice'\nselected_categorical_cols = calculateAnova(X,y, numerical_discrete+ nonselected_numerical_columns + time_columns + cat_columns,'SalePrice')\nselected_categorical_cols","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:30.842798Z","iopub.execute_input":"2022-09-01T10:36:30.843451Z","iopub.status.idle":"2022-09-01T10:36:31.220142Z","shell.execute_reply.started":"2022-09-01T10:36:30.843414Z","shell.execute_reply":"2022-09-01T10:36:31.218790Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"selected_col = [col for col in X.columns \\\n if col in selected_numerical_columns + selected_categorical_cols]\nX = X[selected_col].copy()\nX_test = X_test[selected_col].copy()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:31.221538Z","iopub.execute_input":"2022-09-01T10:36:31.221942Z","iopub.status.idle":"2022-09-01T10:36:31.235079Z","shell.execute_reply.started":"2022-09-01T10:36:31.221891Z","shell.execute_reply":"2022-09-01T10:36:31.233689Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2.3 Cross correlation between attributes","metadata":{}},{"cell_type":"code","source":"correlations=X.corr()\nattrs = correlations.iloc[:-1,:-1] # all except target\n\nthreshold = 0.5\nimportant_corrs = (attrs[abs(attrs) > threshold][attrs != 1.0]) \\\n    .unstack().dropna().to_dict()\n\nunique_important_corrs = pd.DataFrame(\n    list(set([(tuple(sorted(key)), important_corrs[key]) \\\n    for key in important_corrs])), \n        columns=['Attribute Pair', 'Correlation'])\n\n    # sorted by absolute value\nunique_important_corrs = unique_important_corrs.iloc[\n    abs(unique_important_corrs['Correlation']).argsort()[::-1]]\n\nunique_important_corrs.style.background_gradient(axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:31.236707Z","iopub.execute_input":"2022-09-01T10:36:31.237163Z","iopub.status.idle":"2022-09-01T10:36:31.270600Z","shell.execute_reply.started":"2022-09-01T10:36:31.237117Z","shell.execute_reply":"2022-09-01T10:36:31.269626Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"To avoid the Multicollinearity problem, we will delete one feature from each pair of highly\ncorrelated predictors. We have two pairs: the first consists of Garage Cars and Garage Area, and\nthe other consists of Gr Liv Area and TotRms AbvGrd. For the first pair, we will remove Garage\nCars feature; from the second pair, we will remove TotRms AbvGrd feature:","metadata":{}},{"cell_type":"code","source":"X.drop([\"GarageCars\", \"GarageYrBlt\",\"TotRmsAbvGrd\"], axis=1, inplace=True)\nX_test.drop([\"GarageCars\", \"GarageYrBlt\",\"TotRmsAbvGrd\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:31.271849Z","iopub.execute_input":"2022-09-01T10:36:31.272757Z","iopub.status.idle":"2022-09-01T10:36:31.281668Z","shell.execute_reply.started":"2022-09-01T10:36:31.272723Z","shell.execute_reply":"2022-09-01T10:36:31.280408Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2.3 mutual_info_regression","metadata":{}},{"cell_type":"code","source":"def make_mi_scores(X, y):\n    '''Estimate mutual information for a continuous target variable.'''\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\nmi_scores = make_mi_scores(X, y)\nmi_scores.head()\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.figure(figsize=(10,15))\n    clrs = ['grey' if (x < 0.01) else 'blue' for x in scores ]\n    plt.barh(width, scores, color=clrs)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\nplot_mi_scores(mi_scores)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:31.283574Z","iopub.execute_input":"2022-09-01T10:36:31.284443Z","iopub.status.idle":"2022-09-01T10:36:34.483471Z","shell.execute_reply.started":"2022-09-01T10:36:31.284394Z","shell.execute_reply":"2022-09-01T10:36:34.482421Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def corrplot(df, method=\"pearson\", annot=False, **kwargs):\n    plt.figure(figsize=(25,40))\n    sns.clustermap(\n        df.corr(method),\n        vmin=-1.0,\n        vmax=1.0,\n        cmap=\"icefire\",\n        method=\"complete\",\n        annot=annot,\n        **kwargs,\n    )\ncorrplot(X.join(y))","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:34.485046Z","iopub.execute_input":"2022-09-01T10:36:34.485402Z","iopub.status.idle":"2022-09-01T10:36:35.713861Z","shell.execute_reply.started":"2022-09-01T10:36:34.485371Z","shell.execute_reply":"2022-09-01T10:36:35.712706Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"### 3.3  Feature Scaling and Transform","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ndef transform_dataset(dataset, test_data):\n\n    def transform_categoricals(dataset):\n        mp = {'Ex':4,'Gd':3,'TA':2,'Fa':1,'Po':0}\n        dataset['ExterQual'] = dataset['ExterQual'].map(mp)\n        #dataset['ExterCond'] = dataset['ExterCond'].map(mp)\n        dataset['HeatingQC'] = dataset['HeatingQC'].map(mp)\n        dataset['KitchenQual'] = dataset['KitchenQual'].map(mp)\n        mp = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'NA':0}\n        dataset['BsmtQual'] = dataset['BsmtQual'].map(mp)\n        dataset['BsmtCond'] = dataset['BsmtCond'].map(mp)\n        dataset['BsmtExposure'] = dataset['BsmtExposure'].map(\n        {'Gd':4,'Av':3,'Mn':2,'No':1,'NA':0})\n        mp = {'GLQ':6,'ALQ':5,'BLQ':4,'Rec':3,'LwQ':2,'Unf':1,'NA':0}\n        dataset['BsmtFinType1'] = dataset['BsmtFinType1'].map(mp)\n        dataset['BsmtFinType2'] = dataset['BsmtFinType2'].map(mp)\n        dataset['CentralAir'] = dataset['CentralAir'].map({'Y':1,'N':0})\n        dataset['Functional'] = dataset['Functional'].map(\n        {'Typ':7,'Min1':6,'Min2':5,'Mod':4,'Maj1':3,\n        'Maj2':2,'Sev':1,'Sal':0})\n        dataset['FireplaceQu'] = dataset['FireplaceQu'].map(\n        {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'NA':0})\n        dataset['GarageFinish'] = dataset['GarageFinish'].map(\n        {'Fin':3,'RFn':2,'Unf':1,'NA':0})\n        dataset['GarageQual'] = dataset['GarageQual'].map(\n        {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'NA':0})\n        dataset['GarageCond'] = dataset['GarageCond'].map(\n        {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'NA':0})\n        dataset['Fence'] = dataset['Fence'].map(\n        {'GdPrv':4,'MnPrv':3,'GdWo':2,'MnWw':1,'NA':0})\n        return dataset\n    \n    numerical_columns = dataset.select_dtypes(include=[np.number]).columns.tolist()\n    dataset = transform_categoricals(dataset)\n    test_data = transform_categoricals(test_data)\n    scaler = StandardScaler()\n    # We need to fit the scaler to our data before transformation\n    dataset.loc[:, numerical_columns] = scaler.fit_transform(\n    dataset.loc[:, numerical_columns])\n    test_data.loc[:, numerical_columns] = scaler.transform(\n    test_data.loc[:, numerical_columns])\n    \n    cat_cols = dataset.select_dtypes(exclude=[np.number]).columns\n    \n    # Removing uninformative feed\n    dataset = dataset.loc[:,mi_scores>=0.05]\n    test_data = test_data.loc[:,mi_scores>=0.05]\n    dataset = pd.get_dummies(dataset)\n    test_data = pd.get_dummies(test_data)\n\n    return dataset, test_data","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:35.715720Z","iopub.execute_input":"2022-09-01T10:36:35.716812Z","iopub.status.idle":"2022-09-01T10:36:35.736352Z","shell.execute_reply.started":"2022-09-01T10:36:35.716751Z","shell.execute_reply":"2022-09-01T10:36:35.735185Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"X, X_test=transform_dataset(X, X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:35.737844Z","iopub.execute_input":"2022-09-01T10:36:35.738324Z","iopub.status.idle":"2022-09-01T10:36:35.861724Z","shell.execute_reply.started":"2022-09-01T10:36:35.738288Z","shell.execute_reply":"2022-09-01T10:36:35.860574Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## 4. Training Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.svm import SVR\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:35.863165Z","iopub.execute_input":"2022-09-01T10:36:35.863520Z","iopub.status.idle":"2022-09-01T10:36:36.044563Z","shell.execute_reply.started":"2022-09-01T10:36:35.863488Z","shell.execute_reply":"2022-09-01T10:36:36.043370Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"#### 4.1 Splitting the Dataset<a class=\"anchor\" id=\"tr_split\">\n    \nWe need a training dataset to train our model\nand a test dataset to evaluate the model. So we will split our dataset randomly into two parts,\none for training and the other for testing","metadata":{}},{"cell_type":"code","source":"\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y,\ntest_size=0.3, random_state=3)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:36.045933Z","iopub.execute_input":"2022-09-01T10:36:36.046303Z","iopub.status.idle":"2022-09-01T10:36:36.058010Z","shell.execute_reply.started":"2022-09-01T10:36:36.046269Z","shell.execute_reply":"2022-09-01T10:36:36.057190Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2 Training<a class=\"anchor\" id=\"tr_apr\">\n    \nChoose an algorithm that implements the corresponding technique\n    \n- Search for an effective parameter combination for the chosen algorithm\n- Create a model using the found parameters\n- Train (fit) the model on the training dataset\n- Test the model on the test dataset and get the results","metadata":{}},{"cell_type":"markdown","source":"##### 4.2.1 Linear Regression<a class=\"anchor\" id=\"tr_lr\">\nFor Linear Regression, we will choose three algorithmic implementations: Ridge Regression and\nElastic Net.","metadata":{}},{"cell_type":"markdown","source":"###### 4.2.1.1 Ridge Regression","metadata":{}},{"cell_type":"code","source":"parameter_space = {\n\"alpha\": [1, 10, 100, 290, 500],\n\"fit_intercept\": [True, False],\n\"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n}\nclf = GridSearchCV(Ridge(random_state=3), parameter_space, n_jobs=-1,\ncv=5, scoring=\"neg_mean_squared_error\")\nclf.fit(Xtrain, ytrain)\nprint(\"Best parameters:\")\nprint(clf.best_params_)\n\nridge_model = Ridge(random_state=3, **clf.best_params_)\nridge_model.fit(Xtrain, ytrain);\n\nypred = ridge_model.predict(Xtest)\nridge_mse = mean_squared_error(ytest, ypred)\nprint(\"Ridge MSE =\", ridge_mse)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:36.059542Z","iopub.execute_input":"2022-09-01T10:36:36.060126Z","iopub.status.idle":"2022-09-01T10:36:46.757368Z","shell.execute_reply.started":"2022-09-01T10:36:36.060072Z","shell.execute_reply":"2022-09-01T10:36:46.755585Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"parameter_space = {\n\"alpha\": [1, 10, 100, 280, 500],\n\"l1_ratio\": [0.5, 1],\n\"fit_intercept\": [True, False],\n}\nclf = GridSearchCV(ElasticNet(random_state=3), parameter_space,\nn_jobs=-1, cv=5, scoring=\"neg_mean_squared_error\")\nclf.fit(Xtrain, ytrain)\nclf.fit(Xtest, ytest)\nprint(\"Best parameters:\")\nprint(clf.best_params_)\nelasticNet_model = ElasticNet(random_state=3, **clf.best_params_)\nelasticNet_model.fit(Xtrain, ytrain)\nypred = elasticNet_model.predict(Xtest)\nelasticNet_mse = mean_squared_error(ytest, ypred)\nprint(\"Elastic Net MSE =\", elasticNet_mse)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:46.760358Z","iopub.execute_input":"2022-09-01T10:36:46.761348Z","iopub.status.idle":"2022-09-01T10:36:49.575677Z","shell.execute_reply.started":"2022-09-01T10:36:46.761275Z","shell.execute_reply":"2022-09-01T10:36:49.573763Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"parameter_space = \\\n{\n\"max_depth\": [4, 5, 6],\n\"learning_rate\": [0.005, 0.009, 0.01],\n\"n_estimators\": [700, 1000, 2500],\n\"booster\": [\"gbtree\",],\n\"gamma\": [7, 25, 100],\n\"subsample\": [0.3, 0.6],\n\"colsample_bytree\": [0.5, 0.7],\n\"colsample_bylevel\": [0.5, 0.7,],\n\"reg_alpha\": [0.5, 1, 10, 33],\n\"reg_lambda\": [1, 3, 10],\n}\nclf = RandomizedSearchCV(XGBRegressor(random_state=3),\nparameter_space, cv=10, n_jobs=-1,\nscoring=\"neg_mean_squared_error\",\nrandom_state=3, n_iter=20)\nclf.fit(X, y)\nprint(\"Best parameters:\")\nprint(clf.best_params_)\nxgb_model = XGBRegressor(**clf.best_params_)\nxgb_model.fit(Xtrain, ytrain);\ny_pred = xgb_model.predict(Xtest)\nxgb_mse = mean_squared_error(ytest, y_pred)\nprint(\"XGBoost MSE =\", xgb_mse)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:36:49.583763Z","iopub.execute_input":"2022-09-01T10:36:49.586778Z","iopub.status.idle":"2022-09-01T10:47:36.691936Z","shell.execute_reply.started":"2022-09-01T10:36:49.586726Z","shell.execute_reply":"2022-09-01T10:47:36.691029Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"xgb_feature_importances = xgb_model.feature_importances_\nxgb_feature_importances = pd.Series(\nxgb_feature_importances, index=Xtrain.columns.values\n).sort_values(ascending=False).head(15)\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.barplot(x=xgb_feature_importances,\ny=xgb_feature_importances.index,\ncolor=\"#003f5c\");\nplt.xlabel('Feature Importance');\nplt.ylabel('Feature');","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:47:36.693635Z","iopub.execute_input":"2022-09-01T10:47:36.694272Z","iopub.status.idle":"2022-09-01T10:47:37.043354Z","shell.execute_reply.started":"2022-09-01T10:47:36.694169Z","shell.execute_reply":"2022-09-01T10:47:37.042177Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"for x in [x for x in Xtrain.columns\n if x not in X_test.columns]:\n    X_test[x]= 0","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:47:37.045331Z","iopub.execute_input":"2022-09-01T10:47:37.046254Z","iopub.status.idle":"2022-09-01T10:47:37.056998Z","shell.execute_reply.started":"2022-09-01T10:47:37.046183Z","shell.execute_reply":"2022-09-01T10:47:37.055827Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:58:10.058532Z","iopub.execute_input":"2022-09-01T10:58:10.059388Z","iopub.status.idle":"2022-09-01T10:58:10.074638Z","shell.execute_reply.started":"2022-09-01T10:58:10.059329Z","shell.execute_reply":"2022-09-01T10:58:10.073413Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"xgb_model","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:58:28.204511Z","iopub.execute_input":"2022-09-01T10:58:28.205820Z","iopub.status.idle":"2022-09-01T10:58:28.225899Z","shell.execute_reply.started":"2022-09-01T10:58:28.205764Z","shell.execute_reply":"2022-09-01T10:58:28.224494Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"import pickle \nmodel_file = \"model.pickle\"\nwith open(model_file,'wb') as f:\n    pickle.dump(xgb_model, f)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T11:03:58.484713Z","iopub.execute_input":"2022-09-01T11:03:58.486163Z","iopub.status.idle":"2022-09-01T11:03:58.553150Z","shell.execute_reply.started":"2022-09-01T11:03:58.486076Z","shell.execute_reply":"2022-09-01T11:03:58.552153Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"\npredictions = xgb_model.predict(X_test)\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:47:37.058496Z","iopub.execute_input":"2022-09-01T10:47:37.059115Z","iopub.status.idle":"2022-09-01T10:47:37.121050Z","shell.execute_reply.started":"2022-09-01T10:47:37.059063Z","shell.execute_reply":"2022-09-01T10:47:37.120166Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}